{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 17:33:51.142448: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-05 17:33:51.549596: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 17:33:51.549631: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 17:33:51.639674: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 17:33:51.738278: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-05 17:34:02.849477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Using backend: tensorflow.compat.v1\n",
      "Other supported backends: tensorflow, pytorch, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/liruixiang/.conda/envs/deeponet/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enable just-in-time compilation with XLA.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import deepxde as dde\n",
    "from deepxde.backend import tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "Building DeepONetCartesianProd...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liruixiang/.conda/envs/deeponet/lib/python3.9/site-packages/deepxde/nn/tensorflow_compat_v1/deeponet.py:549: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  y_func = tf.layers.dense(\n",
      "/home/liruixiang/.conda/envs/deeponet/lib/python3.9/site-packages/deepxde/nn/tensorflow_compat_v1/deeponet.py:556: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  y_func = tf.layers.dense(\n",
      "/home/liruixiang/.conda/envs/deeponet/lib/python3.9/site-packages/deepxde/nn/tensorflow_compat_v1/deeponet.py:570: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  y_loc = tf.layers.dense(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'build' took 0.602472 s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 17:34:36.940074: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-08-05 17:34:36.940675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16936 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'compile' took 3.700605 s\n",
      "\n",
      "Compiling model...\n",
      "Building DeepONetCartesianProd...\n",
      "'build' took 0.502772 s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 17:34:39.240732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16936 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'compile' took 2.204762 s\n",
      "\n",
      "Warning: epochs is deprecated and will be removed in a future version. Use iterations instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 17:34:40.948371: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 17:34:43.247817: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fc79c0092f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-05 17:34:43.247864: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-08-05 17:34:43.345162: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 17:34:44.138575: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722850489.241190  133471 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step      Train loss    Test loss     Test metric   \n",
      "0         [8.21e-01]    [8.41e-01]    [1.02e+00]    \n",
      "1000      [9.31e-02]    [9.98e-02]    [4.32e-01]    \n",
      "2000      [8.37e-02]    [9.00e-02]    [4.13e-01]    \n",
      "3000      [8.06e-02]    [8.69e-02]    [4.03e-01]    \n",
      "4000      [7.87e-02]    [8.47e-02]    [3.92e-01]    \n",
      "5000      [7.65e-02]    [8.14e-02]    [3.84e-01]    \n",
      "6000      [6.18e-02]    [6.49e-02]    [3.50e-01]    \n",
      "7000      [5.61e-02]    [5.86e-02]    [3.37e-01]    \n",
      "8000      [4.83e-02]    [5.09e-02]    [3.16e-01]    \n",
      "9000      [4.25e-02]    [4.55e-02]    [2.95e-01]    \n",
      "10000     [3.97e-02]    [4.27e-02]    [2.83e-01]    \n",
      "11000     [3.79e-02]    [4.08e-02]    [2.77e-01]    \n",
      "12000     [3.60e-02]    [3.89e-02]    [2.69e-01]    \n",
      "13000     [3.63e-02]    [3.91e-02]    [2.67e-01]    \n",
      "14000     [3.25e-02]    [3.51e-02]    [2.55e-01]    \n",
      "15000     [3.12e-02]    [3.37e-02]    [2.49e-01]    \n",
      "16000     [3.14e-02]    [3.38e-02]    [2.48e-01]    \n",
      "17000     [2.88e-02]    [3.11e-02]    [2.39e-01]    \n",
      "18000     [2.84e-02]    [3.06e-02]    [2.37e-01]    \n",
      "19000     [2.77e-02]    [2.97e-02]    [2.33e-01]    \n",
      "20000     [2.82e-02]    [3.00e-02]    [2.32e-01]    \n",
      "21000     [2.69e-02]    [2.86e-02]    [2.25e-01]    \n",
      "22000     [2.59e-02]    [2.75e-02]    [2.19e-01]    \n",
      "23000     [2.53e-02]    [2.68e-02]    [2.15e-01]    \n",
      "24000     [2.50e-02]    [2.65e-02]    [2.11e-01]    \n",
      "25000     [2.46e-02]    [2.59e-02]    [2.07e-01]    \n",
      "26000     [2.42e-02]    [2.54e-02]    [2.04e-01]    \n",
      "27000     [2.39e-02]    [2.51e-02]    [2.01e-01]    \n",
      "28000     [2.38e-02]    [2.49e-02]    [1.98e-01]    \n",
      "29000     [2.35e-02]    [2.46e-02]    [1.96e-01]    \n",
      "30000     [2.66e-02]    [2.78e-02]    [2.05e-01]    \n",
      "31000     [2.31e-02]    [2.41e-02]    [1.93e-01]    \n",
      "32000     [2.32e-02]    [2.42e-02]    [1.92e-01]    \n",
      "33000     [2.29e-02]    [2.39e-02]    [1.90e-01]    \n",
      "34000     [2.30e-02]    [2.40e-02]    [1.90e-01]    \n",
      "35000     [2.26e-02]    [2.35e-02]    [1.88e-01]    \n",
      "36000     [2.24e-02]    [2.33e-02]    [1.87e-01]    \n",
      "37000     [2.26e-02]    [2.35e-02]    [1.87e-01]    \n",
      "38000     [2.25e-02]    [2.34e-02]    [1.87e-01]    \n",
      "39000     [2.21e-02]    [2.29e-02]    [1.85e-01]    \n",
      "40000     [2.20e-02]    [2.28e-02]    [1.84e-01]    \n",
      "41000     [2.19e-02]    [2.27e-02]    [1.83e-01]    \n",
      "42000     [2.20e-02]    [2.28e-02]    [1.83e-01]    \n",
      "43000     [2.19e-02]    [2.27e-02]    [1.83e-01]    \n",
      "44000     [2.16e-02]    [2.24e-02]    [1.82e-01]    \n",
      "45000     [2.15e-02]    [2.23e-02]    [1.81e-01]    \n",
      "46000     [2.15e-02]    [2.22e-02]    [1.81e-01]    \n",
      "47000     [2.14e-02]    [2.20e-02]    [1.80e-01]    \n",
      "48000     [2.17e-02]    [2.24e-02]    [1.81e-01]    \n",
      "49000     [2.14e-02]    [2.20e-02]    [1.79e-01]    \n",
      "50000     [2.11e-02]    [2.18e-02]    [1.78e-01]    \n",
      "51000     [2.13e-02]    [2.19e-02]    [1.79e-01]    \n",
      "52000     [2.12e-02]    [2.18e-02]    [1.78e-01]    \n",
      "53000     [2.13e-02]    [2.18e-02]    [1.79e-01]    \n",
      "54000     [2.08e-02]    [2.13e-02]    [1.77e-01]    \n",
      "55000     [2.07e-02]    [2.12e-02]    [1.77e-01]    \n",
      "56000     [2.06e-02]    [2.11e-02]    [1.76e-01]    \n",
      "57000     [2.05e-02]    [2.10e-02]    [1.76e-01]    \n",
      "58000     [2.10e-02]    [2.15e-02]    [1.78e-01]    \n",
      "59000     [2.06e-02]    [2.11e-02]    [1.76e-01]    \n",
      "60000     [2.05e-02]    [2.09e-02]    [1.76e-01]    \n",
      "61000     [2.01e-02]    [2.06e-02]    [1.75e-01]    \n",
      "62000     [2.00e-02]    [2.05e-02]    [1.74e-01]    \n",
      "63000     [1.98e-02]    [2.03e-02]    [1.74e-01]    \n",
      "64000     [1.97e-02]    [2.01e-02]    [1.73e-01]    \n",
      "65000     [1.95e-02]    [1.99e-02]    [1.73e-01]    \n",
      "66000     [1.94e-02]    [1.98e-02]    [1.72e-01]    \n",
      "67000     [1.93e-02]    [1.97e-02]    [1.72e-01]    \n",
      "68000     [1.92e-02]    [1.96e-02]    [1.72e-01]    \n",
      "69000     [1.91e-02]    [1.95e-02]    [1.72e-01]    \n",
      "70000     [1.88e-02]    [1.93e-02]    [1.71e-01]    \n",
      "71000     [1.86e-02]    [1.92e-02]    [1.71e-01]    \n",
      "72000     [1.84e-02]    [1.90e-02]    [1.70e-01]    \n",
      "73000     [1.84e-02]    [1.90e-02]    [1.70e-01]    \n",
      "74000     [1.81e-02]    [1.88e-02]    [1.69e-01]    \n",
      "75000     [1.76e-02]    [1.83e-02]    [1.67e-01]    \n",
      "76000     [1.74e-02]    [1.82e-02]    [1.67e-01]    \n",
      "77000     [1.72e-02]    [1.80e-02]    [1.66e-01]    \n",
      "78000     [1.70e-02]    [1.78e-02]    [1.65e-01]    \n",
      "79000     [1.68e-02]    [1.77e-02]    [1.65e-01]    \n",
      "80000     [1.67e-02]    [1.75e-02]    [1.64e-01]    \n",
      "81000     [1.64e-02]    [1.73e-02]    [1.63e-01]    \n",
      "82000     [1.62e-02]    [1.71e-02]    [1.62e-01]    \n",
      "83000     [1.62e-02]    [1.72e-02]    [1.62e-01]    \n",
      "84000     [1.59e-02]    [1.69e-02]    [1.61e-01]    \n",
      "85000     [1.59e-02]    [1.69e-02]    [1.61e-01]    \n",
      "86000     [1.56e-02]    [1.66e-02]    [1.60e-01]    \n",
      "87000     [1.54e-02]    [1.65e-02]    [1.60e-01]    \n",
      "88000     [1.53e-02]    [1.64e-02]    [1.59e-01]    \n",
      "89000     [1.52e-02]    [1.63e-02]    [1.59e-01]    \n",
      "90000     [1.51e-02]    [1.62e-02]    [1.59e-01]    \n",
      "91000     [1.50e-02]    [1.61e-02]    [1.58e-01]    \n",
      "92000     [1.48e-02]    [1.60e-02]    [1.58e-01]    \n",
      "93000     [1.47e-02]    [1.59e-02]    [1.57e-01]    \n",
      "94000     [1.47e-02]    [1.59e-02]    [1.57e-01]    \n",
      "95000     [1.46e-02]    [1.58e-02]    [1.57e-01]    \n",
      "96000     [1.44e-02]    [1.57e-02]    [1.57e-01]    \n",
      "97000     [1.43e-02]    [1.55e-02]    [1.56e-01]    \n",
      "98000     [1.44e-02]    [1.56e-02]    [1.57e-01]    \n",
      "99000     [1.41e-02]    [1.54e-02]    [1.56e-01]    \n",
      "100000    [1.40e-02]    [1.53e-02]    [1.56e-01]    \n",
      "101000    [1.39e-02]    [1.52e-02]    [1.55e-01]    \n",
      "102000    [1.40e-02]    [1.53e-02]    [1.56e-01]    \n",
      "103000    [1.38e-02]    [1.51e-02]    [1.55e-01]    \n",
      "104000    [1.37e-02]    [1.50e-02]    [1.55e-01]    \n",
      "105000    [1.36e-02]    [1.49e-02]    [1.54e-01]    \n",
      "106000    [1.36e-02]    [1.50e-02]    [1.55e-01]    \n",
      "107000    [1.35e-02]    [1.49e-02]    [1.54e-01]    \n",
      "108000    [1.34e-02]    [1.48e-02]    [1.54e-01]    \n",
      "109000    [1.33e-02]    [1.47e-02]    [1.54e-01]    \n",
      "110000    [1.33e-02]    [1.46e-02]    [1.53e-01]    \n",
      "111000    [1.32e-02]    [1.46e-02]    [1.53e-01]    \n",
      "112000    [1.32e-02]    [1.45e-02]    [1.53e-01]    \n",
      "113000    [1.31e-02]    [1.45e-02]    [1.53e-01]    \n",
      "114000    [1.31e-02]    [1.45e-02]    [1.53e-01]    \n",
      "115000    [1.30e-02]    [1.44e-02]    [1.52e-01]    \n",
      "116000    [1.30e-02]    [1.44e-02]    [1.52e-01]    \n",
      "117000    [1.29e-02]    [1.43e-02]    [1.52e-01]    \n",
      "118000    [1.29e-02]    [1.43e-02]    [1.52e-01]    \n",
      "119000    [1.28e-02]    [1.42e-02]    [1.52e-01]    \n",
      "120000    [1.29e-02]    [1.43e-02]    [1.52e-01]    \n",
      "121000    [1.27e-02]    [1.41e-02]    [1.51e-01]    \n",
      "122000    [1.28e-02]    [1.42e-02]    [1.52e-01]    \n",
      "123000    [1.27e-02]    [1.41e-02]    [1.51e-01]    \n",
      "124000    [1.27e-02]    [1.41e-02]    [1.51e-01]    \n",
      "125000    [1.26e-02]    [1.40e-02]    [1.51e-01]    \n",
      "126000    [1.25e-02]    [1.39e-02]    [1.50e-01]    \n",
      "127000    [1.25e-02]    [1.39e-02]    [1.50e-01]    \n",
      "128000    [1.25e-02]    [1.38e-02]    [1.50e-01]    \n",
      "129000    [1.24e-02]    [1.38e-02]    [1.50e-01]    \n",
      "130000    [1.25e-02]    [1.39e-02]    [1.50e-01]    \n",
      "131000    [1.23e-02]    [1.37e-02]    [1.50e-01]    \n",
      "132000    [1.23e-02]    [1.37e-02]    [1.49e-01]    \n",
      "133000    [1.22e-02]    [1.36e-02]    [1.49e-01]    \n",
      "134000    [1.22e-02]    [1.36e-02]    [1.49e-01]    \n",
      "135000    [1.24e-02]    [1.37e-02]    [1.50e-01]    \n",
      "136000    [1.21e-02]    [1.35e-02]    [1.49e-01]    \n",
      "137000    [1.21e-02]    [1.35e-02]    [1.49e-01]    \n",
      "138000    [1.22e-02]    [1.36e-02]    [1.49e-01]    \n",
      "139000    [1.20e-02]    [1.34e-02]    [1.48e-01]    \n",
      "140000    [1.20e-02]    [1.34e-02]    [1.48e-01]    \n",
      "141000    [1.20e-02]    [1.34e-02]    [1.48e-01]    \n",
      "142000    [1.20e-02]    [1.34e-02]    [1.48e-01]    \n",
      "143000    [1.20e-02]    [1.33e-02]    [1.48e-01]    \n",
      "144000    [1.19e-02]    [1.33e-02]    [1.48e-01]    \n",
      "145000    [1.19e-02]    [1.33e-02]    [1.48e-01]    \n",
      "146000    [1.18e-02]    [1.32e-02]    [1.47e-01]    \n",
      "147000    [1.18e-02]    [1.32e-02]    [1.47e-01]    \n",
      "148000    [1.19e-02]    [1.32e-02]    [1.48e-01]    \n",
      "149000    [1.18e-02]    [1.31e-02]    [1.47e-01]    \n",
      "150000    [1.18e-02]    [1.31e-02]    [1.47e-01]    \n",
      "151000    [1.17e-02]    [1.31e-02]    [1.47e-01]    \n",
      "152000    [1.17e-02]    [1.30e-02]    [1.47e-01]    \n",
      "153000    [1.18e-02]    [1.31e-02]    [1.47e-01]    \n",
      "154000    [1.18e-02]    [1.31e-02]    [1.47e-01]    \n",
      "155000    [1.17e-02]    [1.30e-02]    [1.47e-01]    \n",
      "156000    [1.16e-02]    [1.30e-02]    [1.47e-01]    \n",
      "157000    [1.16e-02]    [1.29e-02]    [1.47e-01]    \n",
      "158000    [1.15e-02]    [1.29e-02]    [1.46e-01]    \n",
      "159000    [1.15e-02]    [1.28e-02]    [1.46e-01]    \n",
      "160000    [1.15e-02]    [1.29e-02]    [1.46e-01]    \n",
      "161000    [1.15e-02]    [1.28e-02]    [1.46e-01]    \n",
      "162000    [1.14e-02]    [1.28e-02]    [1.46e-01]    \n",
      "163000    [1.16e-02]    [1.29e-02]    [1.46e-01]    \n",
      "164000    [1.14e-02]    [1.27e-02]    [1.46e-01]    \n",
      "165000    [1.14e-02]    [1.27e-02]    [1.46e-01]    \n",
      "166000    [1.14e-02]    [1.27e-02]    [1.45e-01]    \n",
      "167000    [1.13e-02]    [1.26e-02]    [1.45e-01]    \n",
      "168000    [1.13e-02]    [1.26e-02]    [1.45e-01]    \n",
      "169000    [1.13e-02]    [1.26e-02]    [1.45e-01]    \n",
      "170000    [1.13e-02]    [1.25e-02]    [1.45e-01]    \n",
      "171000    [1.13e-02]    [1.25e-02]    [1.45e-01]    \n",
      "172000    [1.13e-02]    [1.26e-02]    [1.45e-01]    \n",
      "173000    [1.12e-02]    [1.25e-02]    [1.45e-01]    \n",
      "174000    [1.12e-02]    [1.25e-02]    [1.45e-01]    \n",
      "175000    [1.12e-02]    [1.24e-02]    [1.44e-01]    \n",
      "176000    [1.12e-02]    [1.24e-02]    [1.44e-01]    \n",
      "177000    [1.12e-02]    [1.24e-02]    [1.44e-01]    \n",
      "178000    [1.11e-02]    [1.24e-02]    [1.44e-01]    \n",
      "179000    [1.13e-02]    [1.25e-02]    [1.44e-01]    \n",
      "180000    [1.13e-02]    [1.26e-02]    [1.45e-01]    \n",
      "181000    [1.11e-02]    [1.24e-02]    [1.44e-01]    \n",
      "182000    [1.11e-02]    [1.23e-02]    [1.44e-01]    \n",
      "183000    [1.10e-02]    [1.22e-02]    [1.43e-01]    \n",
      "184000    [1.10e-02]    [1.23e-02]    [1.43e-01]    \n",
      "185000    [1.10e-02]    [1.22e-02]    [1.43e-01]    \n",
      "186000    [1.11e-02]    [1.23e-02]    [1.44e-01]    \n",
      "187000    [1.09e-02]    [1.22e-02]    [1.43e-01]    \n",
      "188000    [1.09e-02]    [1.21e-02]    [1.43e-01]    \n",
      "189000    [1.09e-02]    [1.21e-02]    [1.43e-01]    \n",
      "190000    [1.09e-02]    [1.21e-02]    [1.43e-01]    \n",
      "191000    [1.09e-02]    [1.21e-02]    [1.42e-01]    \n",
      "192000    [1.08e-02]    [1.20e-02]    [1.42e-01]    \n",
      "193000    [1.08e-02]    [1.20e-02]    [1.42e-01]    \n",
      "194000    [1.08e-02]    [1.20e-02]    [1.42e-01]    \n",
      "195000    [1.08e-02]    [1.20e-02]    [1.42e-01]    \n",
      "196000    [1.08e-02]    [1.19e-02]    [1.42e-01]    \n",
      "197000    [1.07e-02]    [1.19e-02]    [1.41e-01]    \n",
      "198000    [1.08e-02]    [1.19e-02]    [1.42e-01]    \n",
      "199000    [1.07e-02]    [1.19e-02]    [1.41e-01]    \n",
      "200000    [1.07e-02]    [1.18e-02]    [1.41e-01]    \n",
      "201000    [1.07e-02]    [1.18e-02]    [1.41e-01]    \n",
      "202000    [1.06e-02]    [1.18e-02]    [1.41e-01]    \n",
      "203000    [1.07e-02]    [1.18e-02]    [1.41e-01]    \n",
      "204000    [1.06e-02]    [1.17e-02]    [1.40e-01]    \n",
      "205000    [1.06e-02]    [1.17e-02]    [1.40e-01]    \n",
      "206000    [1.06e-02]    [1.17e-02]    [1.40e-01]    \n",
      "207000    [1.06e-02]    [1.17e-02]    [1.40e-01]    \n",
      "208000    [1.05e-02]    [1.16e-02]    [1.40e-01]    \n",
      "209000    [1.05e-02]    [1.16e-02]    [1.40e-01]    \n",
      "210000    [1.05e-02]    [1.16e-02]    [1.40e-01]    \n",
      "211000    [1.05e-02]    [1.16e-02]    [1.40e-01]    \n",
      "212000    [1.04e-02]    [1.15e-02]    [1.39e-01]    \n",
      "213000    [1.04e-02]    [1.15e-02]    [1.39e-01]    \n",
      "214000    [1.04e-02]    [1.15e-02]    [1.39e-01]    \n",
      "215000    [1.04e-02]    [1.15e-02]    [1.39e-01]    \n",
      "216000    [1.04e-02]    [1.15e-02]    [1.39e-01]    \n",
      "217000    [1.04e-02]    [1.14e-02]    [1.39e-01]    \n",
      "218000    [1.04e-02]    [1.14e-02]    [1.39e-01]    \n",
      "219000    [1.04e-02]    [1.14e-02]    [1.39e-01]    \n",
      "220000    [1.03e-02]    [1.13e-02]    [1.38e-01]    \n",
      "221000    [1.04e-02]    [1.14e-02]    [1.39e-01]    \n",
      "222000    [1.03e-02]    [1.13e-02]    [1.38e-01]    \n",
      "223000    [1.03e-02]    [1.13e-02]    [1.38e-01]    \n",
      "224000    [1.02e-02]    [1.12e-02]    [1.38e-01]    \n",
      "225000    [1.02e-02]    [1.12e-02]    [1.37e-01]    \n",
      "226000    [1.02e-02]    [1.12e-02]    [1.37e-01]    \n",
      "227000    [1.01e-02]    [1.11e-02]    [1.37e-01]    \n",
      "228000    [1.01e-02]    [1.11e-02]    [1.37e-01]    \n",
      "229000    [1.01e-02]    [1.11e-02]    [1.37e-01]    \n",
      "230000    [1.01e-02]    [1.11e-02]    [1.36e-01]    \n",
      "231000    [1.01e-02]    [1.11e-02]    [1.36e-01]    \n",
      "232000    [1.01e-02]    [1.11e-02]    [1.36e-01]    \n",
      "233000    [1.01e-02]    [1.10e-02]    [1.36e-01]    \n",
      "234000    [1.00e-02]    [1.09e-02]    [1.36e-01]    \n",
      "235000    [9.99e-03]    [1.09e-02]    [1.35e-01]    \n",
      "236000    [9.99e-03]    [1.09e-02]    [1.35e-01]    \n",
      "237000    [9.97e-03]    [1.09e-02]    [1.35e-01]    \n",
      "238000    [9.95e-03]    [1.09e-02]    [1.35e-01]    \n",
      "239000    [9.92e-03]    [1.08e-02]    [1.35e-01]    \n",
      "240000    [9.88e-03]    [1.08e-02]    [1.35e-01]    \n",
      "241000    [9.88e-03]    [1.08e-02]    [1.34e-01]    \n",
      "242000    [9.83e-03]    [1.07e-02]    [1.34e-01]    \n",
      "243000    [9.82e-03]    [1.07e-02]    [1.34e-01]    \n",
      "244000    [9.79e-03]    [1.07e-02]    [1.34e-01]    \n",
      "245000    [9.81e-03]    [1.07e-02]    [1.34e-01]    \n",
      "246000    [9.80e-03]    [1.07e-02]    [1.34e-01]    \n",
      "247000    [9.76e-03]    [1.06e-02]    [1.33e-01]    \n",
      "248000    [9.71e-03]    [1.06e-02]    [1.33e-01]    \n",
      "249000    [9.68e-03]    [1.05e-02]    [1.33e-01]    \n",
      "250000    [9.67e-03]    [1.05e-02]    [1.33e-01]    \n",
      "\n",
      "Best model at step 250000:\n",
      "  train loss: 9.67e-03\n",
      "  test loss: 1.05e-02\n",
      "  test metric: [1.33e-01]\n",
      "\n",
      "'train' took 18789.203997 s\n",
      "\n",
      "Warning: epochs is deprecated and will be removed in a future version. Use iterations instead.\n",
      "Training model...\n",
      "\n",
      "Step      Train loss    Test loss     Test metric   \n",
      "0         [4.19e-01]    [4.29e-01]    [1.16e+00]    \n",
      "1000      [8.99e-02]    [9.45e-02]    [6.44e-01]    \n",
      "2000      [8.58e-02]    [9.03e-02]    [6.24e-01]    \n",
      "3000      [7.36e-02]    [7.79e-02]    [5.92e-01]    \n",
      "4000      [7.55e-02]    [8.03e-02]    [6.17e-01]    \n",
      "5000      [4.73e-02]    [5.11e-02]    [5.25e-01]    \n",
      "6000      [5.16e-02]    [5.52e-02]    [5.40e-01]    \n",
      "7000      [4.54e-02]    [4.89e-02]    [5.22e-01]    \n",
      "8000      [4.50e-02]    [4.81e-02]    [5.13e-01]    \n",
      "9000      [4.33e-02]    [4.62e-02]    [5.00e-01]    \n",
      "10000     [4.14e-02]    [4.41e-02]    [4.89e-01]    \n",
      "11000     [4.00e-02]    [4.26e-02]    [4.77e-01]    \n",
      "12000     [3.91e-02]    [4.16e-02]    [4.69e-01]    \n",
      "13000     [3.70e-02]    [3.95e-02]    [4.54e-01]    \n",
      "14000     [3.56e-02]    [3.80e-02]    [4.40e-01]    \n",
      "15000     [3.46e-02]    [3.70e-02]    [4.27e-01]    \n",
      "16000     [3.33e-02]    [3.57e-02]    [4.21e-01]    \n",
      "17000     [3.22e-02]    [3.45e-02]    [4.10e-01]    \n",
      "18000     [3.14e-02]    [3.37e-02]    [4.04e-01]    \n",
      "19000     [3.05e-02]    [3.28e-02]    [3.97e-01]    \n",
      "20000     [2.99e-02]    [3.22e-02]    [3.91e-01]    \n",
      "21000     [2.89e-02]    [3.10e-02]    [3.84e-01]    \n",
      "22000     [2.82e-02]    [3.02e-02]    [3.79e-01]    \n",
      "23000     [2.80e-02]    [2.99e-02]    [3.77e-01]    \n",
      "24000     [2.69e-02]    [2.87e-02]    [3.69e-01]    \n",
      "25000     [2.67e-02]    [2.83e-02]    [3.71e-01]    \n",
      "26000     [2.58e-02]    [2.70e-02]    [3.64e-01]    \n",
      "27000     [2.49e-02]    [2.60e-02]    [3.61e-01]    \n",
      "28000     [2.43e-02]    [2.52e-02]    [3.58e-01]    \n",
      "29000     [2.41e-02]    [2.49e-02]    [3.58e-01]    \n",
      "30000     [2.31e-02]    [2.38e-02]    [3.50e-01]    \n",
      "31000     [2.28e-02]    [2.33e-02]    [3.47e-01]    \n",
      "32000     [2.22e-02]    [2.26e-02]    [3.43e-01]    \n",
      "33000     [2.20e-02]    [2.23e-02]    [3.40e-01]    \n",
      "34000     [2.17e-02]    [2.19e-02]    [3.35e-01]    \n",
      "35000     [2.13e-02]    [2.15e-02]    [3.33e-01]    \n",
      "36000     [2.08e-02]    [2.09e-02]    [3.29e-01]    \n",
      "37000     [2.04e-02]    [2.06e-02]    [3.27e-01]    \n",
      "38000     [2.02e-02]    [2.03e-02]    [3.24e-01]    \n",
      "39000     [2.01e-02]    [2.02e-02]    [3.22e-01]    \n",
      "40000     [1.98e-02]    [1.98e-02]    [3.21e-01]    \n",
      "41000     [1.96e-02]    [1.97e-02]    [3.19e-01]    \n",
      "42000     [1.94e-02]    [1.95e-02]    [3.17e-01]    \n",
      "43000     [1.92e-02]    [1.93e-02]    [3.15e-01]    \n",
      "44000     [1.91e-02]    [1.92e-02]    [3.13e-01]    \n",
      "45000     [1.90e-02]    [1.91e-02]    [3.13e-01]    \n",
      "46000     [1.89e-02]    [1.89e-02]    [3.11e-01]    \n",
      "47000     [1.87e-02]    [1.87e-02]    [3.09e-01]    \n",
      "48000     [1.87e-02]    [1.87e-02]    [3.09e-01]    \n",
      "49000     [1.85e-02]    [1.85e-02]    [3.07e-01]    \n",
      "50000     [1.84e-02]    [1.84e-02]    [3.07e-01]    \n",
      "51000     [1.84e-02]    [1.84e-02]    [3.06e-01]    \n",
      "52000     [1.82e-02]    [1.82e-02]    [3.05e-01]    \n",
      "53000     [1.81e-02]    [1.81e-02]    [3.04e-01]    \n",
      "54000     [1.80e-02]    [1.80e-02]    [3.03e-01]    \n",
      "55000     [1.79e-02]    [1.80e-02]    [3.03e-01]    \n",
      "56000     [1.78e-02]    [1.79e-02]    [3.02e-01]    \n",
      "57000     [1.78e-02]    [1.78e-02]    [3.02e-01]    \n",
      "58000     [1.78e-02]    [1.78e-02]    [3.01e-01]    \n",
      "59000     [1.76e-02]    [1.76e-02]    [3.01e-01]    \n",
      "60000     [1.76e-02]    [1.76e-02]    [3.01e-01]    \n",
      "61000     [1.75e-02]    [1.75e-02]    [3.00e-01]    \n",
      "62000     [1.74e-02]    [1.74e-02]    [3.00e-01]    \n",
      "63000     [1.74e-02]    [1.74e-02]    [3.00e-01]    \n",
      "64000     [1.73e-02]    [1.73e-02]    [2.99e-01]    \n",
      "65000     [1.72e-02]    [1.72e-02]    [2.99e-01]    \n",
      "66000     [1.72e-02]    [1.72e-02]    [2.99e-01]    \n",
      "67000     [1.75e-02]    [1.75e-02]    [3.01e-01]    \n",
      "68000     [1.70e-02]    [1.70e-02]    [2.97e-01]    \n",
      "69000     [1.69e-02]    [1.69e-02]    [2.98e-01]    \n",
      "70000     [1.74e-02]    [1.75e-02]    [3.01e-01]    \n",
      "71000     [1.67e-02]    [1.68e-02]    [2.97e-01]    \n",
      "72000     [1.68e-02]    [1.68e-02]    [2.98e-01]    \n",
      "73000     [1.66e-02]    [1.67e-02]    [2.97e-01]    \n",
      "74000     [1.66e-02]    [1.66e-02]    [2.96e-01]    \n",
      "75000     [1.65e-02]    [1.66e-02]    [2.96e-01]    \n",
      "76000     [1.66e-02]    [1.67e-02]    [2.97e-01]    \n",
      "77000     [1.64e-02]    [1.65e-02]    [2.96e-01]    \n",
      "78000     [1.64e-02]    [1.64e-02]    [2.96e-01]    \n",
      "79000     [1.63e-02]    [1.64e-02]    [2.96e-01]    \n",
      "80000     [1.62e-02]    [1.63e-02]    [2.95e-01]    \n",
      "81000     [1.62e-02]    [1.63e-02]    [2.95e-01]    \n",
      "82000     [1.62e-02]    [1.63e-02]    [2.95e-01]    \n",
      "83000     [1.61e-02]    [1.62e-02]    [2.94e-01]    \n",
      "84000     [1.60e-02]    [1.61e-02]    [2.95e-01]    \n",
      "85000     [1.60e-02]    [1.61e-02]    [2.95e-01]    \n",
      "86000     [1.60e-02]    [1.61e-02]    [2.94e-01]    \n",
      "87000     [1.59e-02]    [1.61e-02]    [2.95e-01]    \n",
      "88000     [1.60e-02]    [1.61e-02]    [2.96e-01]    \n",
      "89000     [1.59e-02]    [1.60e-02]    [2.96e-01]    \n",
      "90000     [1.59e-02]    [1.60e-02]    [2.96e-01]    \n",
      "91000     [1.58e-02]    [1.60e-02]    [2.96e-01]    \n",
      "92000     [1.58e-02]    [1.59e-02]    [2.95e-01]    \n",
      "93000     [1.57e-02]    [1.58e-02]    [2.95e-01]    \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_data(filename, n_train, n_test):\n",
    "    data = scipy.io.loadmat(filename)\n",
    "    x = data[\"x_coor\"].astype(np.float32)\n",
    "    y = data[\"y_coor\"].astype(np.float32)\n",
    "    t = data[\"t\"].astype(np.float32)\n",
    "    Vx = data[\"Vx\"].astype(np.float32)\n",
    "    Vy = data[\"Vy\"].astype(np.float32)\n",
    "    \n",
    "    u = np.stack((Vx, Vy), axis=-1)  # Shape: (N, k, n_points, 2)\n",
    "    u_final = u[:, -1, :, :]  # Shape: (N, n_points, 2)\n",
    "\n",
    "    u_flattened = u.reshape(u.shape[0], u.shape[1], -1) #Input branch only recieves the 1D array\n",
    "    # Branch: initial velocity field\n",
    "    branch = u_flattened[:, 0, :]  # Shape: (N, n_points, 2)\n",
    "    # Trunk: spatial coordinates grid\n",
    "    xy = np.vstack((np.ravel(x), np.ravel(y))).T  # N x 2 (x, y)：grid points\n",
    "    \n",
    "    # Output: velocity field at the final time step\n",
    "\n",
    "\n",
    "    # Split into training and testing data\n",
    "    branch_train = branch[:n_train]\n",
    "    xy_train = xy\n",
    "    u_final_train = u_final[:n_train]\n",
    "\n",
    "    branch_test = branch[-n_test:]\n",
    "    xy_test = xy\n",
    "    u_final_test = u_final[-n_test:]\n",
    "\n",
    "    return (branch_train, xy_train), u_final_train, (branch_test, xy_train), u_final_test\n",
    "\n",
    "def main():\n",
    "    n_train = 100  # Adjust based on your dataset size\n",
    "    n_test = 60  # Adjust based on your dataset size\n",
    "    nx = 6400\n",
    "\n",
    "    data_path = \"/home/liruixiang/data/gepup/train_data_new.mat\"\n",
    "    x_train, u_final_train, x_test, u_final_test = get_data(data_path, n_train, n_test)\n",
    "    \n",
    "    # Split u_final_train and u_final_test into Vx and Vy parts\n",
    "    u_final_train_vx = u_final_train[:, :, 0]\n",
    "    u_final_train_vy = u_final_train[:, :, 1]\n",
    "    u_final_test_vx = u_final_test[:, :, 0]\n",
    "    u_final_test_vy = u_final_test[:, :, 1]\n",
    "    \n",
    "    # train_x = [branch_train, xy_train]\n",
    "    # test_x = [branch_test, xy_test]\n",
    "\n",
    "    # Create datasets for Vx and Vy\n",
    "    data_vx = dde.data.Triple(\n",
    "        x_train, u_final_train_vx,\n",
    "        x_test, u_final_test_vx\n",
    "    )\n",
    "    data_vy = dde.data.Triple(\n",
    "        x_train, u_final_train_vy,\n",
    "        x_test, u_final_test_vy\n",
    "    )\n",
    "\n",
    "    # 创建两个子网络，分别生成Vx和Vy\n",
    "    net_vx = dde.maps.DeepONetCartesianProd(\n",
    "        [nx * 2, 128, 128], [2, 128, 128], \"relu\", \"Glorot normal\"\n",
    "    )\n",
    "\n",
    "    net_vy = dde.maps.DeepONetCartesianProd(\n",
    "        [nx * 2, 128, 128], [2, 128, 128], \"relu\", \"Glorot normal\"\n",
    "    )\n",
    "\n",
    "    # 创建模型\n",
    "    model_vx = dde.Model(data_vx, net_vx)\n",
    "    model_vy = dde.Model(data_vy, net_vy)\n",
    "\n",
    "    # 编译模型\n",
    "    model_vx.compile(\n",
    "        \"adam\",\n",
    "        lr=1e-3,\n",
    "        decay=(\"inverse time\", 1, 1e-4),\n",
    "        metrics=[\"mean l2 relative error\"],\n",
    "    )\n",
    "    model_vy.compile(\n",
    "        \"adam\",\n",
    "        lr=1e-3,\n",
    "        decay=(\"inverse time\", 1, 1e-4),\n",
    "        metrics=[\"mean l2 relative error\"],\n",
    "    )\n",
    "\n",
    "    # 训练模型\n",
    "    losshistory_vx, train_state_vx = model_vx.train(epochs=250000, batch_size=None)\n",
    "    losshistory_vy, train_state_vy = model_vy.train(epochs=250000, batch_size=None)\n",
    "\n",
    "    # 预测\n",
    "    y_pred_vx = model_vx.predict(data_vx.test_x)\n",
    "    y_pred_vy = model_vy.predict(data_vy.test_x)\n",
    "\n",
    "    # 保存预测结果\n",
    "    np.savetxt(\"y_pred_vx_deeponet.dat\", y_pred_vx[0].reshape(nx, 1))\n",
    "    np.savetxt(\"y_pred_vy_deeponet.dat\", y_pred_vy[0].reshape(nx, 1))\n",
    "    np.savetxt(\"y_true_vx_deeponet.dat\", data_vx.test_y[0].reshape(nx, 1))\n",
    "    np.savetxt(\"y_true_vy_deeponet.dat\", data_vy.test_y[0].reshape(nx, 1))\n",
    "    np.savetxt(\"y_error_vx_deeponet.dat\", (y_pred_vx[0] - data_vx.test_y[0]).reshape(nx, 1))\n",
    "    np.savetxt(\"y_error_vy_deeponet.dat\", (y_pred_vy[0] - data_vy.test_y[0]).reshape(nx, 1))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Enable memory growth for GPUs\n",
    "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if physical_devices:\n",
    "        try:\n",
    "            for device in physical_devices:\n",
    "                tf.config.experimental.set_memory_growth(device, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "    \n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeponet",
   "language": "python",
   "name": "deeponet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
