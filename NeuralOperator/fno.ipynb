{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from timeit import default_timer\n",
    "from utilities3 import UnitGaussianNormalizer, LpLoss  # Assuming these are defined in utilities3.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SpectralConv2d(nn.Module):\n",
    "    \"\"\"2D Fourier layer. It does FFT, linear transform, and Inverse FFT.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        # (batch, in_channel, x, y), (in_channel, out_channel, x, y) -> (batch, out_channel, x, y)\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        # Compute Fourier coefficients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNO2d(nn.Module):\n",
    "    \"\"\"\n",
    "    The overall network. It contains 4 layers of the Fourier layer.\n",
    "    1. Lift the input to the desired channel dimension by self.fc0.\n",
    "    2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "        W defined by self.w; K defined by self.conv.\n",
    "    3. Project from the channel space to the output space by self.fc1 and self.fc2.\n",
    "    \n",
    "    input: the solution of the coefficient function and locations (a(x, y), x, y)\n",
    "    input shape: (batchsize, x=s, y=s, c=3)\n",
    "    output: the solution \n",
    "    output shape: (batchsize, x=s, y=s, c=1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, modes1, modes2, width):\n",
    "        super(FNO2d, self).__init__()\n",
    "\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.width = width\n",
    "        self.fc0 = nn.Linear(3, self.width)  # input channel is 3: (a(x, y), x, y)\n",
    "\n",
    "        self.conv0 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv1 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv2 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv3 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        size_x, size_y = x.shape[1], x.shape[2]\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = x1 + x2\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = x1 + x2\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = x1 + x2\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 12800 and the array at index 1 has size 6400",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 129\u001b[0m\n\u001b[1;32m    125\u001b[0m     np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_error_fno.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m, out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m y\u001b[38;5;241m.\u001b[39mreshape(batch_size, nx)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 50\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(x[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :], n_train, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# N x nx\u001b[39;00m\n\u001b[1;32m     49\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(y[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :], n_train, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# N x ny\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m x_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# N x nx x 3\u001b[39;00m\n\u001b[1;32m     51\u001b[0m x_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(x_train)\n\u001b[1;32m     52\u001b[0m u_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(u_train)\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 12800 and the array at index 1 has size 6400"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_data(filename, n_train, n_test):\n",
    "    data = scipy.io.loadmat(filename)\n",
    "    x = data[\"x_coor\"].astype(np.float32)\n",
    "    y = data[\"y_coor\"].astype(np.float32)\n",
    "    Vx = data[\"Vx\"].astype(np.float32)\n",
    "    Vy = data[\"Vy\"].astype(np.float32)\n",
    "\n",
    "    Vx_0 = Vx[:, 0, :]\n",
    "    Vy_0 = Vy[:, 0, :]\n",
    "\n",
    "    Vx_final = Vx[:, -1, :]\n",
    "    Vy_final = Vy[:, -1, :]\n",
    "\n",
    "    a = np.concatenate((Vx_0, Vy_0), axis=-1)\n",
    "    x = np.concatenate((x, x), axis=-1)\n",
    "    y = np.concatenate((y, y), axis=-1)\n",
    "    u = np.concatenate((Vx_final, Vy_final), axis=1)\n",
    "\n",
    "    a_train = a[:n_train]\n",
    "    u_train = u[:n_train]\n",
    "\n",
    "    a_test = a[-n_test:]\n",
    "    u_test = u[-n_test:]\n",
    "\n",
    "    return a_train, u_train, a_test, u_test, x, y\n",
    "\n",
    "def main():\n",
    "\n",
    "    batch_size = 20\n",
    "    learning_rate = 0.001\n",
    "    epochs = 500\n",
    "    step_size = 100\n",
    "    gamma = 0.5\n",
    "\n",
    "    modes1 = 16  # At most nt\n",
    "    modes2 = 16  # At most nx / 2 + 1\n",
    "    width = 64  # Max = 190 in NVIDIA GeForce RTX 2080 Ti, otherwise OOM\n",
    "\n",
    "    nx = 12800\n",
    "    n_train = 80\n",
    "    n_test = 20\n",
    "    data_path = \"/home/liruixiang/data/gepup/train_data.mat\"\n",
    "    a_train, u_train, a_test, u_test, x, y = get_data(data_path, n_train, n_test)\n",
    "\n",
    "    x_normalizer = UnitGaussianNormalizer(torch.from_numpy(a_train))\n",
    "    a_train = x_normalizer.encode(torch.from_numpy(a_train)).numpy()\n",
    "    y_normalizer = UnitGaussianNormalizer(torch.from_numpy(u_train))\n",
    "    u_train = y_normalizer.encode(torch.from_numpy(u_train)).numpy()\n",
    "\n",
    "    x = np.repeat(x[0:1, :], n_train, axis=0)  # N x nx\n",
    "    y = np.repeat(y[0:1, :], n_train, axis=0)  # N x ny\n",
    "    x_train = np.concatenate((a_train[:, :, None], x[:, :, None], y[:, :, None]), axis=-1)  # N x nx x 3\n",
    "    x_train = torch.from_numpy(x_train)\n",
    "    u_train = torch.from_numpy(u_train)\n",
    "    x_train = x_train.unsqueeze(2)  # N x nx x 1 x 3\n",
    "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, u_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    x = np.repeat(x[0:1, :], n_test, axis=0)  # N x nx\n",
    "    y = np.repeat(y[0:1, :], n_test, axis=0)  # N x ny\n",
    "    x_test = np.concatenate((a_test[:, :, None], x[:, :, None], y[:, :, None]), axis=-1)  # N x nx x 3\n",
    "    x_test = torch.from_numpy(x_test)\n",
    "    u_test = torch.from_numpy(u_test)\n",
    "    x_test = x_test.unsqueeze(2)  # N x nx x 1 x 3\n",
    "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, u_test), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = FNO2d(modes1, modes2, width).cuda()\n",
    "    # print(count_params(model))\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    start_time = default_timer()\n",
    "    myloss = LpLoss(size_average=False)\n",
    "    y_normalizer.cuda()\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        t1 = default_timer()\n",
    "        train_l2 = 0\n",
    "        train_mse = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            out = model(x).reshape(batch_size, -1, nx)\n",
    "            out = y_normalizer.decode(out)\n",
    "            y = y_normalizer.decode(y)\n",
    "            \n",
    "            mse = F.mse_loss(out.view(batch_size, -1), y.view(batch_size, -1), reduction='mean')\n",
    "            mse.backward()\n",
    "            \n",
    "            loss = myloss(out.view(batch_size,-1), y.view(batch_size,-1))\n",
    "            optimizer.step()\n",
    "            train_mse += mse.item()\n",
    "            train_l2 += loss.item()\n",
    "    \n",
    "        scheduler.step()\n",
    "    \n",
    "        model.eval()\n",
    "        test_l2 = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "                out = model(x).reshape(batch_size, -1, nx)\n",
    "                out = y_normalizer.decode(out)\n",
    "                test_l2 += myloss(out.view(batch_size,-1), y.view(batch_size,-1)).item()\n",
    "\n",
    "        train_mse /= len(train_loader)\n",
    "        train_l2 /= n_train\n",
    "        test_l2 /= n_test\n",
    "    \n",
    "        t2 = default_timer()\n",
    "        print(\"Epoch: %d, time: %.3f, Train Loss: %.3e, Train l2: %.4f, Test l2: %.4f\" \n",
    "                  % (ep, t2-t1, train_mse, train_l2, test_l2), flush=True)\n",
    "\n",
    "    elapsed = default_timer() - start_time\n",
    "    print('Training time: %.3f'%(elapsed))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x, y = next(iter(test_loader))\n",
    "        x = x.cuda()\n",
    "        out = model(x).reshape(batch_size, -1, nx)\n",
    "        out = y_normalizer.decode(out).cpu().numpy()\n",
    "        y = y.numpy()\n",
    "    np.savetxt(\"y_pred_fno.dat\", out[0])\n",
    "    np.savetxt(\"y_true_fno.dat\", y.reshape(batch_size, nx)[0])\n",
    "    np.savetxt(\"y_error_fno.dat\", out[0] - y.reshape(batch_size, nx)[0])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeponet",
   "language": "python",
   "name": "deeponet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
